---
marp: true
theme: ucla
class: invert
style: 
math: mathjax
paginate: "true"
footer: Week 9 | Ngozi Harrison | Cluster 10C
transition: slide
---


# The Long History of Computational Reason and Algorithmic Culture - Week 9

Spring 2025
Ngozi Harrison 
ngozih@g.ucla.edu
PhD Student, Information Studies

---
# Today
- **Discussion** Share out from Reading Together Activity last week (30min)
- **Watch** What's Behind the Race to Create Artificial General Intelligence (30min)
- **Lecture** Ideologies and Epistemic Cultures (45min)
- **Activity** Reading Together Activity (30min)
- **Lecture** Strategies for Developing Your Paper cont'd (30min)


---

<iframe width="1100" height="615" src="https://www.youtube.com/embed/-bKrMk0RSwY?si=mLmJdoKwtcBsXVch" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>

---

# **Lecture** Ideologies and Epistemic Cultures

---


# Tech Utopia Vs Tech Dystopia


**Utopia**

Techno-Utopia emphasizes how technology will transform the world and lead to a greater life for humanity
Singularity is an example of a techno-utopian vision for humanity

**Dystopia**
Dystopia emphasized the harms and destruction of the world by technology, often as a result of humanity losing control of technology
Blade Runner's LA is an example of a techno-dystopia




---
# This Weeks Readings
- Gebru, T., & Torres, É. P. (2024). The TESCREAL bundle: Eugenics and the promise of utopia through artificial general intelligence. First Monday. https://doi.org/10.5210/fm.v29i4.13636
- Ahmed, S., Jaźwińska, K., Ahlawat, A., Winecoff, A., & Wang, M. (2024). Field-building and the epistemic culture of AI safety. First Monday. https://doi.org/10.5210/fm.v29i4.13626
- Li, P., Yang, J., Islam, M. A., & Ren, S. (2025). Making AI Less “Thirsty”: Uncovering and Addressing the Secret Water Footprint of AI Models (No. arXiv:2304.03271). https://doi.org/10.48550/arXiv.2304.03271


---
# Beliefs Inform Practices

It is important for us to examine the values and beliefs that inform the people who hold power and develop technologies,  technology is not a values free enterprise.




---
# Timnit Gebru
- Earned Bachelor of Science and Master of Science degrees in electrical engineering and her PhD in computer vision from Stanford
- Founder and Executive Director of Distributed AI Research Institute

![bg right:33% w:400](images/Pasted%20image%2020250529205835.png)



---
# Meet the Author Émile Torres
- Earned PhD in Philosophy from Leibniz Universität Hannover in Germany, MS in Neuroscience from Brandies University, and BA in Philosophy from University of Maryland, College Park 
- Previously was a transhumanist and longtermist and published various work on human enhancement, machine superintelligence and the future of humanity
- Current research focuses on TESCREAL ideologies and documenting religious, secular, and scientific movements based on ideas of human extiction and eschatology. 
![bg right:33% w:300](images/Pasted%20image%2020250529204953.png)


---



# TESCREAL IDEOLOGIES

Gebru and Torres argue we should resituate our understanding of various technologies emerging ideologies within the long  history of eugenic thought. They also seeks to break up the binary of the doomer/accelerationist paradigm around AGI.

**T**ranshumanism **E**xtropianism **S**ingularitarianism **C**osmism **R**ationalism **E**ffective **A**ltruism **L**ongtermism

---
## Stanford University and the History of Eugenics

![bg left](images/Pasted%20image%2020250113132926.png)

This is David Starr Jordan, first president of Stanford University and Eugenicist


---
# Eugenics and California

In the early 20th century California was an important center for eugenicist thought. In addition to Stanford University, **The Human Betterment Foundation** was founded in 1928 in Pasadena. Psychologist Lewis Terman was a member and created the **IQ test** in 1916. 

---
# Eugenics is the Science of Human Racial Improvement through Controlled Reproduction

![bg right 100%](images/Pasted%20image%2020250113132741.png)
 [Stanford Eugenics History Project](https://www.stanfordeugenics.com/)

---
# Two Kinds of Eugenics

### Positive Eugenics
Refers to the goal of increasing positive/desirable traits and the overall quality of the human stock. Examples include fitness competitions, telling white people to have more babies, encouraging high IQ people to reproduce
### Negative Eugenics
Refers to attempting to reduce less desirable traits in humans. Outlawing miscegenation, limiting immigration, sterilization


---
# Eschatology

Eschatology is an area of religious studies and theology that focuses on about how varius religious approach the idea of the end of the world, the last days, final judgement and similar ideas. Originally was used for Jewish, Christian, and Muslim beliefs about these concepts. 

---
# Key Figures of Modern Movements
- Ray Kurzweil
- Nick Bostrom
- Eliezer Yudkowsky
- William Macaskill
- Nick Land

---
# Ideology, Technology, and Politics

Technology often appears to be apoltical and objective, however, last quarter we learned how data specifically and technology broadly is always political and related to operations of power. Gebru and Torres challenge us to engage with online ideological movements and subcultures and consider how they inform tech as an industry, narratives around technology, and technologies effect on society


---
# Rationalism
An ideology that emerged from the LessWrong website, founded by Eliezer Yudkowsky in 2009. Rationalists focus on “improving human reasoning and decision making,” and many members believe that advanced AI is “a very big deal for the future of humanity”
(Gebru and Torres)

![bg right 75%](images/Pasted%20image%2020250113133336.png)



---
# Effective Altruism
A movement that could be seen as the twin sibling of Rationalism. Whereas Rationalists aim to maximize their rationality, Effective Altruists strive to maximize their “positive impact” on the world
(Gebru and Torres)



---
# Accelerationism

Accelerationism is the idea that we must accelerate society, technology, or conflict in order to bring about social change. Many different varieties of accelerationism both left wing, right wing, and variants that don't cleanly fit in the left right binary. Many accelerationists build their arguments on their readings of Baudrillard and Deleuze and Guattari.

---
# Accelerationism and AGI
In this context we are mostly talking about the accelerationism movement, ideology, and political philosophy developed by Philosopher Nick Land. Nick Land was previously affiliated with the Cybernetic Culture Research Unit of whom Mark Fisher was also a member. A key source for Nick Land's accelerationist thought is his 2017 essay "A Quick-and-Dirty Introduction to Accelerationism". Nick Land has gradually become more right wing and esoteric, coined the term the dark enlightenment. Other thinkers have taken up his ideas and applied them to AI and argue we need to accelerate the race for AGI to bring about the singularity.


---
# e/acc

e/acc stands for effective accelerationism is the combination of effective altruism (an outgrowth of utilitarianism that emerged from Stanford) and accelerationism. Idea that we must pursue technological progress at all costs.


---
# Epistemic Cultures

---

“We contend that the overlapping communities drawn together by these ideas form one coherent “epistemic community”: a community with clearly-defined shared values and methods of knowledge production (Schopmans, 2022). The impact of this epistemic community, which we hereafter refer to as the “AI safety epistemic community”, extends beyond the community’s bounds: non-profit and for-profit organizations, as well as academic research groups, have begun attracting sizable donations to fund their work.” (Ahmed et al., 2024, p. 1)

---
# What is Epistemology

Epistemology is a brand of philosophy that focuses on the the nature of knowledge, where knowledge comes from, and what it is possible to know.

When we refer to epistemology we are referring to the theory of knowledge

---
# What is Epistemology cont'd
“The term “epistemology” comes from the Greek words “episteme” and “logos”. “Episteme” can be translated as “knowledge” or “understanding” or “acquaintance”, while “logos” can be translated as “account” or “argument” or “reason”. Just as each of these different translations captures some facet of the meaning of these Greek terms, so too does each translation capture a different facet of epistemology itself.” (Steup and Neta, 2024)

---
“In Cetina’s words, “Epistemic cultures are cultures that create and warrant knowledge.” Investigating the social practices they comprise reveals “how we know what we know” [3].” ([Ahmed et al., 2024, p. 2](zotero://select/library/items/LNK38AL9)) ([pdf](zotero://open-pdf/library/items/PIP6PYHT?page=2&annotation=S3DCHXM4))

--- 
# A note on method
Critical technocultural discourse analysis is a methodology developed by Andre Brock to conduct a holistic analysis of information systems and technologies. This method uses critical cultural frameworks to understand technical artifacts as embedded in social beliefs and practices. For the past ten years, CTDA has provided a methodological framework to unsettle the normative grounds of technological discourse and techno-determinism. CTDA has primarily been used to analyze the relationship between users, content creators and social platforms. I argue that CTDA has potential as a powerful method for analyzing AI systems.

Primarily this means understanding the computational system as a complex interplay of artifact, practices, and beliefs

---

![](images/material%201.png)
Estimates have shown training GPT-3 in Microsoft’s  data centers can directly use 700,000 liters of clean freshwater (Li et al., 2023)

---

# Discussion Questions
- In your opinion what should a path to developing AI technologies look like?
- What values and philosophies should guide the development of Machine Learning, NLP, and various AI models


---
# **Lecture** Strategies for Developing Your Paper





# Activity Reading Together
Break up into groups of 2. Using your assigned reading discuss within your group and post a response to the discussion board containing the following:

- 3 big ideas from the reading
- 2 things you found surprising in the reading
- 1 discussion question
- 1 quotation from the reading with citation (MLA or APA)


---

# Strategies for Improving your Paper pt. 2


---
![](ngozi-presentations/images/Pasted%20image%2020250523095611.png)




---
# AXES Highlighting

---
# Define Key terms
As you introduce your argument define key terms, both technical and conceptual, which will provide the foundation for your analysis

---
# Guide to Editing
- Writing isn't linear
- Editing is a process of critically reflecting on your own writing

---
# Local Vs Global Revision
- Local revision focuses on changes to individual words and sentences
- Global revision considers structure, evidence, clarity, flow, and mechanics


---
# Tips for a Strong Essay
- Don't be afraid to be bold in your argument, stand on it
- Take the technology seriously and do due dilligence in terms of research 
- Try to avoid lazy/avoid critique, really think through the implications of your argument
- Don't be dismissive but responsible and thought 
- Not just "AI bad" but we have reasoned criqitus of the limiations and social effects of the narratives around AI and alternatives 
- Don't just take a consumer centric approach but think about all stakeholders including developers, decision makers, economics, consumers, and other members of society