---
marp: true
theme: ucla
class: invert
style: 
math: mathjax
paginate: "true"
footer: Week 6 | Ngozi Harrison | Cluster 10C
transition: slide
---


# The Long History of Computational Reason and Algorithmic Culture - Week 6

Spring 2025
Ngozi Harrison 
ngozih@g.ucla.edu
PhD Student, Information Studies

---
# Today
- **Lecture** Introduction to Fairness, Accountability, and Transparency
- **Discuss** Readings for this week
- **Writing Activity** Investigate that Tech Workshop
- **Writing Workshop** Thesis Statements

---
# Introduction to Fairness, Accountability, and Transparency



---

![](ngozi-presentations/images/Pasted%20image%2020250411082856.png)


---
# History of Fairness
- As we learned in the first half of the quarter, algorithms have a long history, so too does the concept of fairness
- Often fairness is considered as a judicial and political concept

---
# ACM FAccT
ACM FAccT is the Conference on Fairness, Accountability, and Transparency sponsored by the Association of Computing Machinery (ACM). This conference has become the home for researchers who are interested in ethics, fairness, accountability, bias, and transparency from a multidisciplinary perspective

The first FAccT conference was held in New York in 2018


---
# Fairness and Machine Learning
Limitations and Opportunities
By Solon Barocas, Moritz Hardt, and Arvind Narayanan
![bg right:33% w:300](ngozi-presentations/images/Pasted%20image%2020250509075836.png)


---
# Meet the Authors Solon Barocas
- Principal researcher in the NYC lab of Microsoft Research
- Assistant Adjunct Professor in Information Science at Cornell University
- Member of the Fairness, Accountability, Transparency, and Ethics (FATE) research group at Microsoft Research and co-leads the initiative on Artificial Intelligence, Policy, and Practice (AIPP) at Cornell. He also co-founded the ACM conference on Fairness, Accountability, and Transparency (FAccT)
![bg right:33% w:300](ngozi-presentations/images/Pasted%20image%2020250509074744.png)

---
# Meet the Author Moritz Hardt
- Director at the Max Planck Institute for Intelligenct Systems
- Previously Associate Professor for Electrical Engineering and Computer Sciences at UC Berkeley
- Research focuses on the scientific foundations of machine learning and algorithmic decision making with a focus on social questions
![bg right:33% w:300](ngozi-presentations/images/Pasted%20image%2020250509075308.png)

---
# Meet the Author Arvind Narayanan
- Professor of Computer Science at Princeton University
- Director of the Center for Information Technology Policy
- Also the co-author, alongside Sayash Kapoor, of our previous reading AI Snake Oil


![bg right:33% w:300](ngozi-presentations/images/Pasted%20image%2020250509075401.png)

---
Fundamentally Fairness is a moral concept for examining the decisions make by institutional and algorithmic processes. Barocas et al argue that machine learning and bias should not be compared to the subjective judgements of individual humans but institutional decision making. Machine learning obscures and launders. 


---
# Machine Learning Loop

![](ngozi-presentations/images/Pasted%20image%2020250509083059.png)

---
> “The fact that machine learning is “evidence-based” by no means ensures that it will lead to accurate, reliable, or fair decisions. This is especially true when using machine learning to model human behavior and characteristics. Our historical examples of the relevant outcomes will almost always reflect historical prejudices against certain social groups, prevailing cultural stereotypes, and existing demographic inequalities. And finding patterns in these data will often mean replicating these very same dynamics.” (Barocas et al., p. 2)

---
# Algorithmic Fairness and Legitimacy
One sense of algorithmic fairness is just about individual outcomes but also the overall legitimacy of algorithmic decision making and the legitimacy of the organizations and individuals deploying it


---
# Formalizing Fairness
There are various approaches for formalizing the measurement of how fair a ML system or algorithm is using statistical techniques and causal models. 
Demographic parity, Similarity, Counterfactuals

---
![](ngozi-presentations/images/Pasted%20image%2020250509081009.png)

---
# Meet the Author Abeba Birhane
- Cognitive Scientist researching human behavior, social systems and responsible and ethical AI
- Recently Finished PhD at University College Dublin 
- Senior Fellow in Trustworthy AI at Mozilla Foundation and Adjuct Lecturer/Assistant Professor at Trinity College Dublin in Computer Science and Statistics
![bg right:33% w:300](ngozi-presentations/images/Pasted%20image%2020250509084940.png)


---
# Meet the Author Inioluwa Deborah Raji
- Fellow at the Mozilla Foundation, has also worked with Prof. Buolamwini and the Algorithmic Justice League
- Currently a CS PhD Student at UC Berkeley

![bg right:33% w:300](ngozi-presentations/images/Pasted%20image%2020250509085039.png)


---
# AI Audits
“Definition 1: An audit is defined as any independent assessment of an identified audit target via an evaluation of articulated expectations with the implicit or explicit objective of accountability.” (Birhane et al., 2024, p. 2)

![bg right:50% w:500](ngozi-presentations/images/Pasted%20image%2020250509084228.png)

---
# How are audits conducted
- Harms Discovery
- Standards Identification
- Performance Analysis
- Audit Communication and Advocacy

---
# **Discussion** 
- How do you determine if an algorithmic decision is fair?
- What does fairness mean? What is the difference between fairness and justice?
- What are the limitations of audits?
- How do we address the limits of auditing AI technologies?

---
# **Writing Activity** Investigate that Tech Workshop